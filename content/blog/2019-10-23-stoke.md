+++
title = "Reimplementation of STOKE for BRIL"
extra.bio = """
Eashan Garg is an undergraduate studying CS and English.
"""
extra.author = "Eashan Garg"
+++

## Are optimizers good enough?

Traditional compiler optimizations target specific aspects of a program, such as dead-code or loops. While extremely effective, these techniques rarely find the *most* optimal sequence of instructions. What if we could somehow sample the space of all programs equivalent to the original, and select the one with the best performance guarantees?

## Introducing STOKE

While sampling the entire program space sounds great in theory, in practice it doesn't work so well. As programs get larger, the set of equivalent instruction-sequences grows exponentially, and evaluating them all becomes a daunting task. STOKE, a type of *superoptimizer*, attempts to solve this problem using MCMC, or random search techniques, to explore these programs. To guide its search path the algorithm uses a cost framework to measure how well a candidate program performs under our predefined heuristics.

There are a few limitations to this technique, most notably that it can only perform on loop-free sequences of code. For this specific implementation, I added a few additional constraints to make the sample space more manageable for my poor Windows laptop (enumerated upon in the following sections).

**Note**: I found this approach to be reminiscent of similarly thorny problem in machine learning - hyperparameter optimization. In the landmark paper "Random Search for Hyper-Parameter Optimization", the authors Bergstra and Bengio show that a random search is actually more efficient than a discrete, exhaustive search in high-dimensional spaces when the functions we are interested in are of low effective dimensionality. While it's hard to replicate the same optimization path each time, it's cool to see that these techniques seem to work surprisingly well.

*Constraining the sample space in order to make it easier to look through*
### Transforming programs

First, we need a way to actually generate samples from our program space. If we construct these programs completely at random, we risk 'bogo-sorting' for an unconstrained number of iterations. Rather, we can use a target program as our *base*, and apply small, guided transformations until the program is optimal. Lets consider three major transformations, each with equal probability of selection:

1. Drop a random instruction
2. Swap two random instructions
3. Replace the arguments of an existing instruction

### Verifying correctness

The above transformations are applied at random, so there are no guarantees that the generated program will do what the original programmer intended, let alone be more performant. We start by verifying that this new representation replicates the exact same behavior as the original.

In the original STOKE algorithm, 
### Evaluating performance

### Exploring the sample space

## How does it do?

### Correctness

### Optimization Performance

### Superoptimizers, hard to say
